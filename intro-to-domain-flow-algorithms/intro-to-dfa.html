<!DOCTYPE html>
<html lang="en">
	<head>
		<title>Introduction to Domain Flow Algorithms</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<style>
			* {
				box-sizing: border-box;
				-moz-box-sizing: border-box;
			}

			body {
				color: #000;
				#font-family: "Courier New";
				font-size: 20px;

				background-color: #fff;
				margin: auto;
				padding: .5in;
				max-width: 10in;
				text-align: justify;
			}

			.view {
				width: 7in;
				height: 7in;
				margin: auto;
			}

			#index_space_view {
				width: 7in;
				height: 7in;
				margin: auto;
			}

			#wavefront_view_1 {
				width: 7in;
				height: 7in;
				margin: auto;
			}

			#wavefront_view_2 {
				width: 7in;
				height: 7in;
				margin: auto;
			}

			#c {
				position: fixed;
				left: 0px; top: 0px;
				width: 100%;
				height: 100%;
				background-color: #fff;
				z-index: -1;
			}

			#info {
				position: absolute;
				top: 0px; width: 6.5in;
				padding: 0px;
				text-align: center;
			}

			a {
				color: #0080ff;
			}

			.math {

				text-align: center;

			}

			.math-frac {

				display: inline-block;
				vertical-align: middle;

			}

			.math-num {

				display: block;

			}

			.math-denom {

				display: block;
				border-top: 1px solid;

			}

			.math-sqrt {

				display: inline-block;
				transform: scale(1, 1.3);

			}

			.math-sqrt-stem {

				display: inline-block;
				border-top: 1px solid;
				margin-top: 5px;

			}

		</style>
	</head>
	<body>

		<canvas id="c"></canvas>

		<div id="info"><a href="http://www.stillwater-sc.com" target="_blank"></a></div>

		<script src="js/build/three.js"></script>
		<script src="js/controls/OrbitControls.js"></script>
		<script src="js/Detector.js"></script>
		<script src="js/lib/numeric-1.2.6.js"></script>

		<script type="x-shader/x-vertex" id="vertexshader">

			attribute float size;
			attribute vec3 customColor;

			varying vec3 vColor;

			void main() {

				vColor = customColor;

				vec4 mvPosition = modelViewMatrix * vec4( position, 1.0 );

				gl_PointSize = size * ( 300.0 / -mvPosition.z );

				gl_Position = projectionMatrix * mvPosition;

			}

		</script>

		<script type="x-shader/x-vertex" id="wavefrontshader">
			uniform float time;
			uniform float cardinality;
			attribute float schedule;
			attribute float size;
			attribute vec3 customColor;

			varying vec3 vColor;

			void main() {

				vColor = customColor;

				vec4 mvPosition = modelViewMatrix * vec4( position, 1.0 );

				// scale particles as objects in 3D space that modulate in size as a computational wavefront passes through
				float period = mod(time, cardinality);  // set a modulo range so the visualization cycles

				// modulate a full sinusoid long: (sin(-pi/2), sin(3*pi/2))
				if (period > (schedule - 1.0) && period < (schedule + 1.0)) {

				    gl_PointSize = (1.5 + sin((period - schedule)*3.14 + 1.57)) * ( 300.0 / length( mvPosition.xyz ) );

				} else {

				    gl_PointSize = size * ( 100.0 / -mvPosition.z );

				}

				gl_Position = projectionMatrix * mvPosition;

			}

		</script>

		<script type="x-shader/x-vertex" id="wavefrontshader2">
			uniform float time;
			uniform float cardinality;
			attribute float schedule;
			attribute float size;
			attribute vec3 customColor;

			varying vec3 vColor;

			void main() {

				vColor = customColor;

				vec4 mvPosition = modelViewMatrix * vec4( position, 1.0 );

				// scale particles as objects in 3D space that modulate in size as a computational wavefront passes through
				float period = mod(time, cardinality);  // set a modulo range so the visualization cycles

				// modulate a full sinusoid long: (sin(-pi/2), sin(3*pi/2))
				if (period > (schedule - 1.0) && period < (schedule + 1.0)) {

				    gl_PointSize = (1.5 + sin((period - schedule)*3.14 + 1.57)) * ( 300.0 / length( mvPosition.xyz ) );

				} else {

				    gl_PointSize = size * ( 100.0 / -mvPosition.z );

				}

				gl_Position = projectionMatrix * mvPosition;

			}

		</script>

		<script type="x-shader/x-fragment" id="fragmentshader">

			uniform vec3 color;
			uniform sampler2D texture;

			varying vec3 vColor;

			void main() {

				gl_FragColor = vec4( color * vColor, 1.0 );

				gl_FragColor = gl_FragColor * texture2D( texture, gl_PointCoord );

				if ( gl_FragColor.a < ALPHATEST ) discard;

			}

		</script>
		<script>
			if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

			var scenes = [];
			var views = [];
			var t, canvas, renderer;
			var PARTICLE_SIZE = 2;
			var clock = new THREE.Clock( true );

			window.onload = init;

			function init() {
                canvas = document.getElementById( 'c' );

                renderer = new THREE.WebGLRenderer( { canvas: canvas, antialias: true } );
                renderer.setClearColor( 0xffffff );
                renderer.setPixelRatio( window.devicePixelRatio );

                views.push( document.getElementById( 'index_space_view' ) );
                views.push( document.getElementById( 'wavefront_view_1' ) );
                views.push( document.getElementById( 'wavefront_view_2' ) );

				{ // views[0] = index_space_view
                    var lattice0 = createIndexSpaceGeometry(20, 20, 20, 1, true);
                    var pointSize0 = PARTICLE_SIZE * 0.5;
                    var scene0 = createIndexSpaceScene( lattice0, pointSize0 );
                    scene0.userData.view = views[0];

                    // PerspectiveCamera ( fov, aspectRatio, near clipping plane, var clipping plane )
                    var camera0 = new THREE.PerspectiveCamera( 75, 1, 0.1, 1000 );
                    camera0.position.set( 0, 0, 25 );   // ( x = 0, y = 0, z = 25 )
                    scene0.userData.camera = camera0;

                    var controls0 = new THREE.OrbitControls( camera0, views[0] );
                    controls0.minDistance = 20;   // zoom can't zoom in further than z = 20
                    controls0.maxDistance = 500;   // zoom can't zoom out further than z = 500
                    scene0.userData.controls = controls0;

                    scenes.push( scene0 );
				}

				{ // views[1] = wavefront_view_1  animate free schedule
                    var lattice1 = createIndexSpaceGeometry(20, 20, 20, 1, false, true);
                    var pointSize1 = PARTICLE_SIZE * 0.5;

                    // cardinality of the simulation is from [3, 60]
                    uniforms1 = {
                        cardinality: { value: 60.0 },
                        time:        { value: 1.0 },
                        color:       { value: new THREE.Color( 0xffffff ) },
                        texture:     { value: new THREE.TextureLoader().load( "textures/sprites/ball.png" ) }
                    };
                    var scene1 = createFreeScheduleWavefrontScene( lattice1, pointSize1, 'wavefrontshader', uniforms1, schedule );
                    scene1.userData.view = views[1];

                    // PerspectiveCamera ( fov, aspectRatio, near clipping plane, var clipping plane )
                    var camera1 = new THREE.PerspectiveCamera( 75, 1, 0.1, 1000 );
                    camera1.position.set( 25, 25, 25 );   // ( x = 0, y = 0, z = 25 )
                    scene1.userData.camera = camera1;

                    var controls1 = new THREE.OrbitControls( camera1, views[1] );
                    controls1.minDistance = 20;   // zoom can't zoom in further than z = 20
                    controls1.maxDistance = 500;   // zoom can't zoom out further than z = 500
                    scene1.userData.controls = controls1;

                    scenes.push( scene1 );
				}

                { // views[2] = wavefront_view_2  animate linear schedule
                    var lattice2 = createIndexSpaceGeometry(20, 20, 20, 1, false, false);
                    var pointSize2 = PARTICLE_SIZE * 0.5;

                    // cardinality of the simulation is from [3, 60]
                    uniforms2 = {
                        cardinality: { value: 60.0 },
                        time:        { value: 1.0 },
                        color:       { value: new THREE.Color( 0xffffff ) },
                        texture:     { value: new THREE.TextureLoader().load( "textures/sprites/ball.png" ) }
                    };
                    var scene2 = createWavefrontScene( lattice2, pointSize2, 'wavefrontshader2', uniforms2, schedule );
                    scene2.userData.view = views[2];

                    // PerspectiveCamera ( fov, aspectRatio, near clipping plane, var clipping plane )
                    var camera2 = new THREE.PerspectiveCamera( 75, 1, 0.1, 1000 );
                    camera2.position.set( 25, 25, 25 );   // ( x = 25, y = 25, z = 25 )
                    scene2.userData.camera = camera2;

                    var controls2 = new THREE.OrbitControls( camera2, views[2] );
                    controls2.minDistance = 20;   // zoom can't zoom in further than z = 20
                    controls2.maxDistance = 500;   // zoom can't zoom out further than z = 500
                    scene2.userData.controls = controls2;

                    scenes.push( scene2 );
                }

				t = 0;
				animate();

			}

			function updateSize() {
				var width = canvas.clientWidth;
				var height = canvas.clientHeight;

				if ( canvas.width !== width || canvas.height != height ) {
					renderer.setSize( width, height, false );
				}
			}

			function animate() {
				render();
				requestAnimationFrame( animate );
			}

            function schedule( tau, index ) {
                return numeric.dot(tau, index);
            }

			function render() {
				updateSize();

				// the ScissorTest machinery is needed to make the viewport clipping work properly.
				renderer.setClearColor( 0xffffff );
				renderer.setScissorTest( false );
				renderer.clear();

				renderer.setClearColor( 0x000000 );
				renderer.setScissorTest( true );

				scenes.forEach( function( scene ) {

					var rect = scene.userData.view.getBoundingClientRect();
					// check if it's off-screen. If so skip it
					if ( rect.bottom < 0 || rect.top  > renderer.domElement.clientHeight ||
						 rect.right  < 0 || rect.left > renderer.domElement.clientWidth ) {
						return;  // it's off-screen so skip the renderering
					}

					// set the viewport
					var width  = rect.right - rect.left;
					var height = rect.bottom - rect.top;
					var left   = rect.left;
					var bottom = renderer.domElement.clientHeight - rect.bottom;
					renderer.setViewport( left, bottom, width, height );
					renderer.setScissor( left, bottom, width, height );

					uniforms1.time.value = t;
					uniforms2.time.value = t;
					renderer.render( scene, scene.userData.camera );

					scene.children[0].geometry.verticesNeedUpdate = true;

				} );

				t = clock.getElapsedTime();
			}

			function createIndexSpaceGeometry( N, M, K, cellSize, center, matmul ) {
			    var lattice = new THREE.Geometry();

			    if (center) {
                    for ( var i = -N/2; i <= N/2; i++ ) {
                        for ( var j = -M/2; j <= M/2; j++ ) {
                            for ( var k = -K/2; k <= K/2; k++ ) {
                                lattice.vertices.push( new THREE.Vector3( i * cellSize, j * cellSize, k * cellSize ) );
                            }
                        }
                    }
				} else {
                    for ( var i = 0; i < N; i++ ) {
                        for ( var j = 0; j < M; j++ ) {
                            for ( var k = 0; k < K; k++ ) {
                                if (matmul) {
                                    // create the lattices for a, b, and c recurrences
                                    lattice.vertices.push( new THREE.Vector3( i * cellSize, j * cellSize, k * cellSize ) );
                                    lattice.vertices.push( new THREE.Vector3( i * cellSize, j * cellSize, k * cellSize ) );
                                    lattice.vertices.push( new THREE.Vector3( i * cellSize, j * cellSize, k * cellSize ) );
								} else {
                                    lattice.vertices.push( new THREE.Vector3( i * cellSize, j * cellSize, k * cellSize ) );
								}
                            }
                        }
                    }
				}

				return lattice;
			}

            function createIndexSpaceScene( lattice, pointSize ) {
                var scene = new THREE.Scene();
                // var geometry1 = new THREE.BoxGeometry( 200, 200, 200, 16, 16, 16 );
                var vertices = lattice.vertices;

                var positions = new Float32Array( vertices.length * 3 );
                var colors    = new Float32Array( vertices.length * 3 );
                var sizes     = new Float32Array( vertices.length );

                var vertex;
                var color = new THREE.Color();

                for ( var i = 0, l = vertices.length; i < l; i++ ) {
                    vertex = vertices[i];
                    vertex.toArray( positions, i * 3 );

                    color.setHSL( 0.01 + 0.1 * ( i / l ), 1.0, 0.5 );
                    color.toArray( colors, i * 3 );

                    sizes[ i ] = pointSize;
                }

                var geometry = new THREE.BufferGeometry();
                geometry.addAttribute( 'position', new THREE.BufferAttribute( positions, 3 ) );
                geometry.addAttribute( 'customColor', new THREE.BufferAttribute( colors, 3 ) );
                geometry.addAttribute( 'size', new THREE.BufferAttribute( sizes, 1 ) );

                var material = new THREE.ShaderMaterial( {
                    uniforms: {
                        color:    { value: new THREE.Color( 0xffffff ) },
                        texture:  { value: new THREE.TextureLoader().load( "textures/sprites/ball.png" ) }
                    },

                    vertexShader: document.getElementById( 'vertexshader' ).textContent,
                    fragmentShader: document.getElementById( 'fragmentshader' ).textContent,

                    alphaTest: 0.9
                } );

                particles = new THREE.Points( geometry, material );
                scene.add( particles );

                return scene;
            }

            function createFreeScheduleWavefrontScene( lattice, pointSize, shader, uniforms, timingFunction ) {
                var scene = new THREE.Scene();
                var vertices = lattice.vertices;

                var positions = new Float32Array( vertices.length * 3 );
                var colors    = new Float32Array( vertices.length * 3 );
                var sizes     = new Float32Array( vertices.length );
                var timing    = new Float32Array( vertices.length );

                var vertex;
                var color = new THREE.Color();

                for ( var i = 0, l = vertices.length; i < l; i = i + 3 ) {
                    // vertex coordinates of a, b, and c points are the same
                    vertex = vertices[i];
                    vertex.toArray( positions, i * 3 );
                    vertex = vertices[i+1];
                    vertex.toArray( positions, (i+1) * 3 );
                    vertex = vertices[i+2];
                    vertex.toArray( positions, (i+2) * 3 );

                    // color of the points are the same
                    // color.setHSL( 0.01 + 0.1 * ( i / l ), 1.0, 0.5 );
					color.setHSL( 0.75, 1.0, 0.5);
                    color.toArray( colors, i * 3 );
                    color.setHSL( 0.5, 1.0, 0.5);
                    color.toArray( colors, (i+1) * 3 );
                    color.setHSL( 0, 1.0, 0.5);
                    color.toArray( colors, (i+2) * 3 );

                    // size is the same
                    sizes[ i ]   = pointSize;
                    sizes[ i+1 ] = pointSize;
                    sizes[ i+2 ] = pointSize;

                    // timing is not
                    timing[ i ]   = timingFunction( [0,1,0], [ vertex.x, vertex.y, vertex.z ]);
                    timing[ i+1 ] = timingFunction( [1,0,0], [ vertex.x, vertex.y, vertex.z ]);
                    timing[ i+2 ] = timingFunction( [1,1,1], [ vertex.x, vertex.y, vertex.z ]);
                }

                var geometry = new THREE.BufferGeometry();
                geometry.addAttribute( 'position', new THREE.BufferAttribute( positions, 3 ) );
                geometry.addAttribute( 'customColor', new THREE.BufferAttribute( colors, 3 ) );
                geometry.addAttribute( 'size', new THREE.BufferAttribute( sizes, 1 ) );
                geometry.addAttribute( 'schedule', new THREE.BufferAttribute( timing, 1 ) );

                var material = new THREE.ShaderMaterial( {
                    uniforms: uniforms,
                    vertexShader: document.getElementById( shader ).textContent,
                    fragmentShader: document.getElementById( 'fragmentshader' ).textContent,

                    alphaTest: 0.9
                } );

                particles = new THREE.Points( geometry, material );
                scene.add( particles );

                return scene;
            }

            function createWavefrontScene( lattice, pointSize, shader, uniforms, timingFunction ) {
                var scene = new THREE.Scene();
                var vertices = lattice.vertices;

                var positions = new Float32Array( vertices.length * 3 );
                var colors    = new Float32Array( vertices.length * 3 );
                var sizes     = new Float32Array( vertices.length );
                var timing    = new Float32Array( vertices.length );

                var vertex;
                var color = new THREE.Color();

                for ( var i = 0, l = vertices.length; i < l; i++ ) {
                    vertex = vertices[i];
                    vertex.toArray( positions, i * 3 );

                    color.setHSL( 0.01 + 0.1 * ( i / l ), 1.0, 0.5 );
                    color.toArray( colors, i * 3 );

                    // size is the same
                    sizes[ i ]   = pointSize;

                    // timing is not
                    timing[ i ]   = timingFunction( [1,1,1], [ vertex.x, vertex.y, vertex.z ]);
                }

                var geometry = new THREE.BufferGeometry();
                geometry.addAttribute( 'position', new THREE.BufferAttribute( positions, 3 ) );
                geometry.addAttribute( 'customColor', new THREE.BufferAttribute( colors, 3 ) );
                geometry.addAttribute( 'size', new THREE.BufferAttribute( sizes, 1 ) );
                geometry.addAttribute( 'schedule', new THREE.BufferAttribute( timing, 1 ) );

                var material = new THREE.ShaderMaterial( {
                    uniforms: uniforms,
                    vertexShader: document.getElementById( shader ).textContent,
                    fragmentShader: document.getElementById( 'fragmentshader' ).textContent,

                    alphaTest: 0.9
                } );

                particles = new THREE.Points( geometry, material );
                scene.add( particles );

                return scene;
            }

		</script>

		<h1>Introduction to Domain Flow Algorithms</h1>
		<p>
			Domain Flow algorithms are parallel algorithms that incorporate the constraints of space and time.
			By honoring the delay that is inherent to the operation of information exchange between two physically
			separate computation or storage sites, domain flow algorithms can improve performance, and most
			importantly, lower energy consumption, as compared to computational models that are based on sequential
			execution.

			These benefits are particularly important for embedded, real-time applications, such as computer vision,
			sensor fusion, and in general, autonomous intelligent systems.
		</p>


		<p>
			Let's take a look at an example of a simple, but valuable operator: dense matrix multiplication.
			A Domain Flow Algorithm for matrix multiply is shown here:
		</p>

		<pre><code>
			compute ( (i,j,k) | 1 <= i,j,k <= N ) {
				a: a[i,j-1,k]
				b: b[i-1,j,k]
				c: c[i,j,k-1] + a[i,j-1,k] * b[i-1,j,k]
			}
		</code></pre>

		<p>
			This algorithm defines a domain of computation governed by a set of constraints, and a set of
			computational dependencies that implicitly define a partial order. For example, we can't execute the result
			for c[i,j,k] until we have computed the result for c[i,j,k-1].
		</p>

		<p>
			From an algorithm design perspective, an explicit dependency allows us to 'order' the
			computational graph. This can be done in time, as is customary in sequential programming, where
			we treat the dependency as an opportunity to sequence computations so that they can be executed
			by a single computational unit that is reused. But for parallel algorithms, we can also
			use this dependency to order the computational events in space. In the parallel design perspective,
			we are looking for (partial) orders where independent computational events are physically separated
			in space.
		</p>

		<p>
			If we look back again at the domain flow algorithm of matrix multiply, we observe that all results
			are assigned to a unique variable. This is called Single Assignment Form, and this yields a
			computational graph that makes all computational dependencies explicit.

			The second observation is that the computational events are made unique with a variable name and
			an index tag, such as [i,j,k]. Thirdly, dependencies between computational events are specified
			by an index expression, such as [i,j-1,k].
		</p>

		<h2>Why are Domain Flow Algorithms specified this way?</h2>

		<p>
			To appreciate the domain flow algorithms and what they enable, you need to think about the physical
			form a 'program evaluator', or processor, could take. In the days when a processor occupied the volume
			of a small room, any physical computational machine was limited to a single computational element.
			This implied that the execution of any algorithm had to be specified as a complete order in time.
			At each step of the execution, the computational element would need to read the input operands, execute
			an instruction, and write the results back. The reading and writing of operands was from and to a
			Random Access Memory.
		</p>

		<p>
			This sequential approach has been very successful, as it is a general purpose mechanism to execute
			any algorithm. But it is not the most energy efficient approach to execute all algorithms. This is
			the niche that domain flow fills: algorithms that exhibit complex, inherently parallel, but geometrically
			constrained concurrency patterns offer the opportunity to be evaluated in a more energy efficient manner.
			The venerable matrix multiply is a good introduction to this class of algorithms,
			more formally defined by the term <i>systems of affine recurrence equations</i>.
		</p>

		<p>
			To arrive at the underlying execution model of domain flow algorithms, we take the other extreme compared
			to fully sequential execution.
			Remember, nodes in the graph represent computational events, and links in the graph represent information exchanges.
			Imagine that we have as many computational resources as there are nodes in the single assignment form
			computational graph. In that case, we can simple 'embed' the computational graph in 3D space.
			However, since a physical machine that would be able to evaluate a node in the graph will have
			some physical extent, a collection of physical nodes will fill 3D space in some 'regular', crystalline
			pattern. Or if we are conceptualizing the space presented by a VLSI chip's surface, it will be a 2D space.
			These crystalline patterns are typically referred to as a <i>lattice</i>, and thus
			the design of a domain flow algorithm is the act of finding space, time, and energy efficient embeddings
			of some computational graph in N-dimensional space.
		</p>

		<p>
			Back to our matrix multiply. We can now reinterpret the domain flow algorithm as a physical embedding.
			Each index range, that is, the i, j, and k in the constraint set, can be seen as a dimension in 3D space.
			The index tag, such as [i,j,k] can then be interpreted as a location in 3D space, more accurately,
			a location in the 3D Cartesian lattice.
		</p>
		<p>
			This is what that lattice looks like for a given N:
		</p>

		<div id="index_space_view">_</div>

		<p>
			We alluded to the fact that inherently-parallel algorithms exhibit some partial order and not a complete order
			because the instructions that can execute independently do not have any explicit order among each other.
			This extra degree of freedom is another benefit domain flow algorithms exhibit over sequential algorithms.
			It allows the execution engine to organize any resource contention in a more energy, space, or time efficient way,
			as long the machine does not violate the dependency	relationships specified in the algorithm.
		</p>
		<p>
			Typically, the complete order defined by sequential algorithms over-constrains the execution order, and
			parallelizing compilers can't recover the inherent dependency structure of the mathematics behind the algorithm,
			leading to disappointing speed-ups. This is a fundamental limitation to trying to generate parallel
			execution models from sequential specifications.

			Instead, the domain flow specification removes this over-constraint and only expresses the data dependencies.
			If we would present the algorithm with instantaneous access to its inputs, then the
			data dependencies inherent to the algorithm would evolve in what is called the free schedule.
		</p>
		<p>
			The free schedule for our matrix multiply is visualized in the following simulation.
		</p>

		<div id="wavefront_view_1">_</div>

		<p>
			But a physical system wouldn't have infinite resources, and certainly not infinite bandwidth.
			The free schedule of a parallel algorithm tends to be unrealizable.
			Let's go through the thought experiment what the free schedule requires of a physical system.
			In the free schedule animation, the propagation recurrences distributing the A and B matrix elements
			throughout the 3D lattice run 'ahead' of the actual computational recurrence calculating the C matrix
			elements.
			The A and B elements arrive at their destination earlier than the time they are consumed by a
			computational event. A physical system would need to have memory to hold these early operands until
			all of the operands are present and the computation can commence. The extra memory required to hold
			these operands is consuming area and energy and thus an attribute that an algorithm designer
			would want to optimize out of the system.
		</p>
		<p>
			Looking more closely at the wavefront that expresses the evolution of the C matrix elements, we
			can observe that the wavefront evolves as a 2D plane with normal <i>[1 1 1]<sup>T</sup></i>.
			This implies that if we <i>constrain</i> the A and B propagations to evolve along this same wavefront
			then all memory requirements would disappear as we deliver the A and B matrix elements just in time
			to participate in the computational event c: c[i,j,k] + a[i,j-1,k] * b[i-1, j,k].
		</p>
		<p>
			This constrained, <i>linear</i> schedule is shown in the next animation.
		</p>
		<div id="wavefront_view_2">_</div>

		<p>
			This particular schedule is called <i>memoryless</i>, that is, no memory is required to execute along this
			evolution. Another way to look at this is that the memory function is provided by the network and the act of
			communicating operands between locations in the lattice. From an energy perspective, this is attractive as
			no additional energy is required to read or write from scratch memories that are needed just to align operand
			timing. As mentioned before, the operands are delivered to the computation in a just-in-time manner.
		</p>

		<p>
			Another observation we can make is that this memoryless, linear schedule exhibits <i>O(N<sup>2</sup>)</i>
			concurrency. The index space is <i>O(N<sup>3</sup>)</i>, but the concurrency of the algorithm is just
			<i>O(N<sup>2</sup>)</i>. This implies that we can create a custom execution engine for
			this execution pattern that only uses <i>O(N<sup>2</sup>)</i> resources and still would be unconstrained.
		</p>
		<p>
			If we compare the concurrency requirements of the free schedule with our memoryless, linear schedule we
			see that the free schedule exhibits resource requirements of the order of <i>O(N<sup>3</sup>)</i>:
			the A and B recurrences race ahead of the computation and occupy resources as they are waiting for the
			computation to consume them. The free schedule is interesting from a theoretical perspective as it
			shows us the unconstrained evolution, or inherent concurrency, of the algorithm. But for building an
			actual, efficient computational engine, the free schedule tends to be too expensive.
		</p>
	</body>
</html>
